## 异步编程的历史演进
[异步编程的历史演进](https://www.cnblogs.com/cnhk19/p/17035882.html)

背景：
计算机硬件技术发展到瓶颈期，CPU运算速度几乎不会再有提升，并且随着互联网的发展，我们的应用将面临越来越多的请求压力。当硬件能力无法提升的时候，我们就不得不比以往更加需要对软件和系统层面进行优化了。

计算机有个非常显著的特点，就是不同硬件的访问速度有着天壤之别，比如内存和磁盘的访问速度区别。这让几乎所有的优化都是围绕这个点来进行。

我们需要关注的是内存访问和网络请求以及磁盘访问的耗时数量级

由于 CPU 内部做了很多优化（比如流水线），我们可以粗略地认为执行一条指令时间约是 1ns（几个时钟周期）。而内存访问大概是 100ns 的数量级，也就是比执行一条指令慢 100 倍；从 ssd 上随机读取一次的时间是 16000ns 级别，而从机械磁盘读取一次，则需要 2000000ns=2ms。我们无时无刻都在使用的网络，横跨大西洋跑一个来回需要的时间约 150000000ns=150ms。你可以看到，相比这些硬件，CPU 的运行速度真的是太快太快了。或许 ns 级单位不直观，那可以把它换成我们更熟悉的秒来感受下。假如 CPU 执行一条指令是 1 秒，那么访问内存需要 1 分 40 秒，从 SSD 上随机读取一次数据需要 4 小时 24 分钟，从磁盘读取一次数据需要 23 天多，一次横跨大西洋的网络请求则需要 4.8 年…你现在可以直观地感受到 CPU 有多么快了吧。

但是快也有快的烦恼，正所谓无敌是多么寂寞。正因为 CPU 速度太快，从 CPU 的角度来说，那其它硬件的速度太慢了（相对论？）。然而关键问题是，我们程序的运算几乎都会依赖这些“慢”硬件，比如在硬盘上读取某些文件的数据到内存中，再对这些数据进行运算。这就不得不面临一个问题，由于某条指令依赖于从硬盘加载的数据，CPU 为了执行这条指令就不得不等到硬盘数据加载完。比如要执行answer = a+1，但是 a 存在磁盘上。为了执行一条 1ns 的加法运算，CPU 却等了 20000000ns，有种等到宇宙尽头的感觉。

为此，计算机先驱们设计了支持分时任务的操作系统。这个分支任务可以粗略地对应成我们常说地线程。操作系统以线程作为最小调度执行单位，线程代表一个独立的计算任务，当遇到需要费时的操作时，操作系统就把当前线程停下，让CPU去执行其他的线程任务，这样CPU就不需要为了执行一个几纳秒的任务而去等待几百万纳秒。如果操作系统调度得当，就可以大大提高CPU的利用率，在相同的时间里面执行多得多的任务。

在20年前，利用多线程就是解决并发的最主流方案，当时最流行的apache服务器就是多线程模型，来一个请求就新建一个线程去处理，操作系统负责回收和调用这些线程。这在当年是没有问题的，想想20年前网络不发达，没有手机。因此服务器的访问量并不大。然后针对今时今日，多线程的不足很快就暴露出来了。尤其是在web领域

为什么web领域是一个典型呢？因为大多数web服务都是IO密集型，通常都是
```
收到请求->查数据库->RPC别的几个服务->组合一下数据->返回
```
在这个过程中，CPU的参数其实很少，绝大部分时间都是在等待DB响应以及等待下游服务的响应。如果使用多线程模型来做web server,你就会发现，虽然操作系统有很多线程，但绝大部分都处于等待网络响应或等待磁盘读取中，CPU的利用率很低，而且CPU都耗时在系统的线程调度上。并且随着并发请求量的增大，线程的开销的不容忽视，每个线程都有自己独有的堆栈空间，一般默认是8M,1000个线程，就会需要占用8G内存。加上线程切换时的开销，每次切换，操作系统需要保存当前线程的各种寄存器数据，后续才能恢复线程继续执行。当线程数量大的时候，这个开销也是客观的。

因此，即使多线程是最直观最简单理解且操作系统天然支持的解决并发的方案，但是由于系统面临的并发数越来越大，在有限的资源下，我们也不得不找到更好的解决方法。

进入主题：异步
> 异步的目的不是让单个任务执行得更快，而是为了让计算机在相同时间内可以完成更多任务。

其实异步是个庞大的体系：主要分为三个方面
- 硬件
- 操作系统
- 异步编程范式

首先硬件是支持异步的根本，但我们还是关注"异步编程体系"，聊到异步最常见的关键词就是：IO多路复用，epoll,libev,回调地狱，async/await等等

初步理解异步的收益

从这段简单的代码开始
```
let number = read("number.txt");
print(number+1);
```
以上代码一开始从磁盘上读取number.txt文件，因为去访问磁盘需要消耗很长时间，所以要完成read+print,总的耗时是不会变的，因为不管是同步还是异步，都需要去访问number.txt拿到number,再进行number+1。

>单个异步任务绝不会比同步任务执行得快

我们用异步得最大目的就是充分利用CPU资源。接着上面的例子，假如操作系统提供了一个 read_async 函数，调用它之后能够立刻返回一个对象，我们后续可以通过这个对象来判断读取操作是否完成了。来看看我们的代码可能会有什么变化：

```
let operation = read_async("number.txt");
let number = 0;
while true {
  if operation.is_finish() {
    number = operation.get_content();
    break;
  }
}
print(number+1);
```
似乎变得更糟了！！由于必须要确定 number 的值才能执行 print，因此即使我们立刻拿到一个 operation 对象，我们除了不停地询问它是否就绪以外，也没有别的办法了。CPU 使用率倒是实打实提高了，但是全部都用在了不断询问操作是否就绪这个循环上了。和之前的同步代码相比，做同样的任务，这样的异步代码耗费了相同的时间，却花费了多得多的 CPU，但是却并没有完成更多的任务。这样写异步代码，除了更费电别无它用，还让代码变得更复杂！！那异步的价值到底在哪里？

接着上面的例子，我稍微变化一下：
```
let a = read("qq.com");
let b = read("jd.com");
print(a+b);
```
假如单个网络请求耗时 50ms，忽略 print 的耗时，那么上面这段代码总耗时就是 100ms。我们再用异步看看：
```
let op_a = read_async("qq.com");
let op_b = read_async("jd.com");
let a = “”;
let b = “”;
while true {
  if op_a.is_finish() {
    a = op_a.get_content();
    break;
  }
}
while true {
  if op_b.is_finish() {
    b = op_b.get_content();
    break;
  }
}
print(a+b);
```
同样，即使是异步读取，程序中立刻返回了，但是也是要等到至少 50ms 以后才有结果返回。但是这里差别就出来了。当 CPU 一直循环执行op_a.is_finish()50ms 以后，它终于完成了，此时 a 有了确定的值。然后程序继续询问 op_b。这里要注意了，一开始程序连续执行两个异步请求，这两个请求同时发送出去了，理想情况下它们可以同时完成。也就是说很可能在 50.001ms 时，op_b 也就绪了。那么这段异步代码最终执行耗时就是 50ms 左右，相比同步代码节约了整整一半的时间。
> 异步并不会让逻辑上串行得任务变快，只能让逻辑上可以并行得任务执行更快。

虽然以上异步代码执行速度更快了，但是它也付出了额外的代价。同步代码虽然执行耗时 100ms，但是 CPU 可以认为一直处于“休眠状态”；而以上异步代码中，CPU 却一直在不断地询问操作是否完成。速度更快，但更费电了！！

## 结合同步的优势
在上面的同步代码中，执行一个同步调用，操作系统会把当前线程挂起，等调用成功后再唤醒线程继续执行，这个过程中 CPU 可以去执行别的线程的任务，而不会空转。如果没有别的任务，甚至可以处于半休眠状态。这说明了一个关键问题，即操作系统是完全知道一个磁盘读取或者网络调用什么时候完成的，只有这样它才能在正确的时间唤醒对应线程（操作系统在这里用到的技术就是中断，这不在本文的范围内就不多讨论了）。既然操作系统有这个能力，那么假如操作系统提供这样一个函数：
```
fn wait_until_get_ready(Operation) -> Response {
  // 阻塞任务，挂起线程，直到operation就绪再唤起线程
}
```
有了这个函数，那我们的异步代码就可以这么写：
```
let op_a = read_async("qq.com");
let op_b = read_async("jd.com");
let a = wait_until_get_ready(op_a);
let b = wait_until_get_ready(op_b);
print(a+b);
```
线程并行得的执行read_async("qq.com")，read_async("jd.com") 这两个任务。这两个是异步的，操作系统会马上返回一个对象，方便我们执行下面的逻辑，当调用wait_until_get_ready(op_a)时，op_a还没有就绪，操作系统就挂起当前线程，直到50ms以后op_a就绪了。操作系统会唤起当前线程继续执行逻辑，这个过程就像执行同步阻塞代码一样不消耗CPU资源，然后继续执行wait_until_get_ready(op_b)，发现op_b也就绪了，这样，我们就可以利用异步代码，只花费50ms,并且不花费额外的CPU资源，就能完成这个任务。

要让我们的异步代码能够做到这一点，其实依赖两个关键因素：
- read_async把任务交给操作系统后能够立刻返回，而不会一直阻塞到它执行完毕，通过这个能力，我们可以让逻辑上没有依赖的任务并发执行
- wait_util_get_ready 依赖于操作系统的通知能力，不用自己去轮询，大大节约CPU资源

## 从0开始进化成JavaScript
在实际场景中，真正并发几个没有关联的任务然后等待他们执行结束其实并不多见，大多数是有逻辑依赖关系的，在有逻辑依赖关联的情况下，我们的代码将变成难以实现和理解
我们继续前面的例子(稍作修改)：
```
let op_a = read_async("qq.com");
let op_b = read_async("jd.com");
let a = wait_until_get_ready(op_a);
write_to("qq.html", a);
let b = wait_until_get_ready(op_b);
write_to("jd.html", b);
```
之前我们假设每个异步请求耗时都是 50ms，但其实绝大多数时候是无法做出这种假设的，尤其是在网络环境下，两个网络请求很大概率响应时长不一样，这个很容易理解。当我们发出两个并发请求后，其实并不知道哪个请求会先响应。我假设 qq.com 的响应时长是 50ms，而 jd.com 的响应时长是 10ms，那么上面的程序会有什么问题呢？

如果我们先let a = wait_until_get_ready(op_a);，此时线程会阻塞直到 op_a 就绪，也就是 50ms 以后才能继续执行后面的语句。但其实 op_b 早在第 10ms 就已经有响应了，但我们的程序并没有及时去处理。这里的根本原因就是，我们写代码时并不知道每个异步请求会在什么时刻完成，只能按照某种特定顺序来执行 wait_until_get_ready 操作，这样势必会造成效率低下。怎么办呢？

这里的问题就出在 wait_until_get_ready 只支持 wait 一个异步操作，不好用。那我们可以考虑给开发操作系统的 Linux Torvads 大爷提需求，系统需要支持这样的两个函数：

```
fn add_to_wait_list(operations: Vec<Operation>)
fn wait_until_some_of_them_get_ready() ->Vec<Operation>
```
通过add_to_wait_list 向全局监听器注册需要监听的异步操作，然后利用wait_until_some_of_them_get_ready,如果没有事件就绪就阻塞线程等待，当注册的异步操作就绪时，就唤醒线程并返回一个数据数组告诉调用方哪些操作就绪了，如果监听队列为空时，wait_until_some_of_them_get_ready 不会阻塞而直接返回一个空数组。可以想象，当 Linux Torvads 排了几个 User Story 让操作系统支持了这两个功能并给我提供了库函数之后，我们的异步代码就可以更进一步：
```
let op_a = read_async("qq.com");
let op_b = read_async("jd.com");
add_to_wait_list([op_a, op_b]);
while true {
  let list = wait_until_some_of_them_get_ready();
  if list.is_empty() {
    break;
  }
  for op in list {
    if op.equal(op_a) {
      write_to("qq.html", op.get_content());
    } else if op.equal(op_b) {
      write_to("jd.html", op.get_content());
    }
  }
}
```
通过这个方式，我们的程序能够及时的响应异步操作，避免盲目地等待，收到一个响应就能立刻输出一个文件

不过仔细想想，可以发现还有两个问题，第一个就是异步操作耗时不同，每次wait_until_some_of_them_get_ready返回的可能是一个异步操作，也可能是多个，因此我们必须要通过一个while不断地询问wait,直到队列的所有异步操作就绪为止，第二个问题就是返回一个就绪的异步操作队列，每个异步操作后续的逻辑可能都不一样，我们必须要先判断是什么事件就绪才能执行对应的逻辑，因此不得不做一个很复杂的循环比较，想象一下，有一万个异步操作对应一万个逻辑。那我们这个循环的代码得多么复杂一万个switch case分支，所以怎么办呢

其实很简单，由于operationde和就绪后要执行的逻辑是一一对应的，因此我们可以直接把对应的后续执行函数绑定到operation上，比如：
```
function read_async_v1(targetUrl:String,callback:function)
{
    let operation = read_async(targetUrl);
    operation.callback=callback;
    return operation;
}
```
这样我们可以创建异步任务时就绑定上它后续的逻辑，也就是所谓的回调函数。然后我们while循环内部就彻底清爽了，而却避免了一次O(n)的循环匹配。这是不是就是C++所谓的动态派发。

```
//第一个异步任务以及异步后续逻辑操作
let op_a = read_async_v1("qq.com",function(data){
    send_to("pony@qq.com",data);
})
//第二个异步任务以及异步后续逻辑操作
let op_b = read_async_v1("jd.com",function(data)
{
    write_To("jd.html",data);
})
add_To_wait_list{[op_a,op_b]};
while true
{
    let list = wait_until_some_of_them_get_ready();
    if list.is_empty()
    {
        break;
    }
    for op in list
    {
        op.callback(op.get_content());
    }
}

```
这里的关键的一步是，read_async返回的operation对象需要能够支持绑定回调函数。
```
function read_async_v2(target,callback){
    let operation = read_async(target);
    operation.callback = callback;
    add_to_wait_list([operation]);
}
```
这样我们的代码就可以简化：
```
read_async_v2("qq.com",function(data)
{
    send_to("qq.html",data);
})
read_async_v2("jd.com",function(data)
{
    write_to("jd.html",data);
})
while true {
    let list = wait_until_some_of_them_get_ready();
    if list.is_empty()
    {
        break;
    }
    for op in list
    {
        op.callback(op.get_content);
    }
}
```
由于我们把后续逻辑都绑定到operation上了，每个异步操作都需要在最后执行上述的while循环来等待异步事件就绪，然后执行其回调。因此如果我们有机会设计一门语言，那就可以将这段while逻辑放在语言的运行时里，让用户不需要每次都在最后加这么一段while代码。经过这个改造后，我们的代码就变成：
```
read_async_v2("qq.com",function(data)
{
    send_to("qq.html",data);
});
read_async_v2("jd.com",function (data)
{
    write_to("jd.html",data);
});

//编译器帮我们把while循环自动插到这里
//或者什么异步框架帮我们做while循环
```
你看，这就像javascript了，JS V8引擎帮我们执行了while循环，也就是JS里大家常说EventLoop.
可以看到，其实我们没有运用任何黑魔法，只依赖几个操作系统的基本元语就可以很自然的过渡到javaScript的异步编程模型。

再简单回顾一下：
- 为了让程序在同一时间里处理更多的请求，我们采用多线程，多线程虽然编写简单，但是对内存和CPU资源消耗大，因此我们考虑利用系统的异步接口进行开发。
- 我不知道异步操作什么时候结束，只能不断轮询它的状态，当有多个异步操作，每个响应的时间都未知，不知道该先去轮询那个，。我们利用操作系统提供的能力，把异步加入到全局的监听队列，然后通过wait_until_some_of_them_get_ready 来等待任意异步任务就绪，所谓的EventLoop
- 当事件就绪时EventLoop不知道该执行什么逻辑，只能进行一个非常复杂判断才能确认后续逻辑该执行那个函数，因为我们给每个异步事件注册回调函数，这样EventLoop的实现就高效清爽了
- 所有异步程序都需要在最后执行EvenLoop，等待事件就绪之后执行回调，因为就可以将EventLoop这块逻辑放到语言自身的runtime中。不需要开发人员自己写。

我们上述利用到的wait_until_some_of_them_get_ready对应的真实的操作系统就是linux的epoll,Mac的kqueue以及windown的iocp,其实C和C++很多异步框架也是类似思路，比如redis使用的libevent以及nodejs使用的libuv.这些框架的共同特点就是，他们提供了多种异步的IO接口，支持事件注册以及通过回调来进行异步编程。只是像C代码，由于不支持闭包，基于它实现的异步操程序，就会比较难理解。












